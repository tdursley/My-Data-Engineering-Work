{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# I.  PySpark RDD â€“ Resilient Distributed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1.  Overview\n",
    "\n",
    "> PySpark's core component, RDD, provides a fault-tolerant, distributed collection of objects with immutability and logical partitioning, enabling parallel computation across cluster nodes.\n",
    "RDDs are collections of objects like Python lists, but computed on multiple processes across physical servers, unlike Python collections which live and process in one process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2.  PySpark RDD Benefits\n",
    "\n",
    "+ **In-Memory Processing:** PySpark loads data from disk and processes it in memory, unlike MapReduce which is I/O intensive.\n",
    "+ **Immutability:** PySpark RDDs are immutable, meaning they cannot be modified once created.\n",
    "+ **Fault Tolerance:** PySpark operates on fault-tolerant data stores like HDFS and S3, automatically reloading data from other partitions if any RDD operation fails.\n",
    "+ **Lazy Evolution:** PySpark evaluates all transformations as it encounters them, not just the first RDD action.\n",
    "+ **Partitioning:** By default, RDDs are partitioned to the number of available cores when created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3.  PySpark RDD Limitations\n",
    "\n",
    "> PySpark RDDs are not suitable for web application storage systems that update state stores, as traditional update logging and data checkpointing systems like databases are more efficient. RDDs aim to provide an efficient programming model for batch analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.4.   RDD Creation\n",
    "\n",
    "> The two ways to create RDDs in PySpark are:\n",
    "> + parallelizing an existing collection\n",
    "> + Referencing a dataset in an external storage system such as HDFS, S3 (AWS), Azure, etc.\n",
    "\n",
    "Before everything, we should first initialise a SparkSession (entry point of any PySpark Application) using the builder pattern method defined in SparkSession class.\n",
    "\n",
    "**Note:** Creating SparkSession object, internally creates one SparkContext per JVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the system environment for Windows & Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"JDK 8\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the system environment for Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"JDK 8/Contents/Home\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/28 17:57:12 WARN Utils: Your hostname, Toms-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.69 instead (on interface en0)\n",
      "25/01/28 17:57:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/28 17:57:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[*]\") \\\n",
    "      .appName(\"PySparkApplication\") \\\n",
    "      .getOrCreate()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">+ **Master():** Uses master name for cluster-run tasks, typically yarn or mesos.\n",
    ">+ **Local[x]:** Determines number of partitions for RDDs in Standalone mode. Ideally, match CPU cores for optimal performance.\n",
    ">+ **AppName():** Sets application name.\n",
    ">+ **getOrCreate():** Returns existing SparkSession object or creates new one if not present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.1.  Using sparkContext.parallelize() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The parallelize() function of SparkContext allows for the creation of an RDD by loading the existing collection from the driver program, which is necessary when data is already in memory from a file or database."
   ]
  },
  {
   "attachments": {
    "cce53526-e061-4cfa-ae23-bfe7c365e1e2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:cce53526-e061-4cfa-ae23-bfe7c365e1e2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD from parallelize    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > To make it simple for this PySpark RDD course we are using files from the local system or loading it from the python list to create RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.2.  Using sparkContext.textFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Use the **textFile()** method to read a *.txt* file into RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/owner/OneDrive/Data Engineering/data_eng.txt\"  # Replace this path with yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD from external Data source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.3.  Using sparkContext.wholeTextFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **wholeTextFiles()** function returns a PairRDD with the key being the file path and the value being file content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read entire file into a RDD as single record.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.4.  Create empty RDD using sparkContext.emptyRDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using **emptyRDD()** method on sparkContext we can create an RDD with no data. This method creates an empty RDD with no partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty RDD with no partition    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.5.  Creating empty RDD with partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sometimes we may need to write an empty RDD to files by partition, In this case, you should create an empty RDD with partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty RDD with partition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.5.   RDD Partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">When we use parallelize(), textFile() or wholeTextFiles() methods of SparkContxt to initiate RDD, it automatically splits the data into partitions based on resource availability. When you run it on a laptop, it creates partitions as the same number of cores available on your system.\n",
    "\n",
    "**getNumPartitions()** â€“ This is an RDD function that returns a number of partitions your dataset split into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get partition count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parallelize manually** â€“ We can also set a number of partitions manually, all we need is to pass a number of partitions as the second parameter to these functions for example;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set partitions manually\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.6.  Repartition and Coalesce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Sometimes, we may need to repartition the RDD, PySpark provides two ways to repartition; first using **repartition()** method, which shuffles data from all nodes also called *full shuffle* and second **coalesce()** method which shuffles data from minimum nodes, for examples if you have data in 4 partitions and doing coalesce(2) moves data from just 2 nodes.  \n",
    "\n",
    ">Both of these functions take the number of partitions to repartition RDD as shown below.  Note that repartition() method is a very expensive operation as it shuffles data from all nodes in a cluster.\n",
    "\n",
    "**Note:** *repartition()* or *coalesce()* methods also return a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition the RDD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop \"PySparkApplication\"\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.7. PySpark RDD Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">RDD operations are the core transformations and actions performed on RDDs\n",
    "\n",
    ">**RDD transformations** â€“ Transformations are lazy operations; instead of updating an RDD, these operations return another RDD.\n",
    ">\n",
    ">**RDD actions** â€“ operations that trigger computation and return RDD values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.1.  Common RDD Transformations functions with example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) flatmap() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flatMap() transformation in the RDD API flattens the resulting RDD after applying a function to each element, producing a new RDD. In the provided example below, each record is initially split by space within an RDD, and subsequently, the transformation flattens it. The resulting RDD comprises individual records, each containing a single word.â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Spark session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_rdd = SparkSession.builder\\\n",
    "    .config(\"spark.driver.host\", \"localhost\")\\\n",
    "    .appName('RDD_Transformations')\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD\n",
    "\n",
    "file_path = \"C:/Users/owner/OneDrive/Data Engineering/RDD_trans.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print RDD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using flatMap()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying collect() to see the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) map() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The map() transformation is used to perform various complex operations, such as adding or updating an element. The result of map t>ransformations retains the same number of records as the input.\n",
    ">\n",
    ">In our word count example, we are adding a new column with value 1 for each word, the result of the RDD is PairRDDFunctions which >contains key-value pairs, word of type String as Key and 1 of type Int as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using map()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The flatMap() transformation is similar to the map() transformation but with one key difference: it allows each input element to map to zero or more output elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) reduceByKey() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The *reduceByKey()* combines the values associated with each key using the provided function. In our scenario, it aggregates the word strings by using the sum function on the corresponding values. The result of our RDD outcome comprises distinct words along with their respective counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reduceByKey()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) sortByKey() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*sortByKey()* transformation is used to sort RDD elements on key. In our example, first, we convert RDD[(String,Int]) to RDD[(Int,String]) using map transformation and later apply sortByKey which ideally does sort on an integer value. And finally, foreach with println statement prints all words in RDD and their count as key-value pair to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortByKey()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) filter() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*filter()* transformation is used to filter the records in an RDD. In our example we are filtering all words starts with â€œoâ€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.2.  Common RDD Actions functions with example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD Action operations trigger the execution of transformations on RDDs (Resilient Distributed Datasets) and produce a result that can be either returned to the driver program or saved to an external storage system.\n",
    "\n",
    "We will continue to use our word count example and perform some actions on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) count() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Returns the number of records in an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Action - count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) first() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Returns the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action - first\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) max() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Returns max record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action - max\n",
    "data = [34,2,56,9,10,41,837]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) reduce() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Reduces the records to single, we can use this to count or sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action - reduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) take() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Returns the record specified as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action - take\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) collect() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Returns all data from RDD as an array. Be careful when you use this action when you are working with huge RDD with millions and billions of data as you may run out of memory on the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action - collect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) saveAsTextFile() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Using saveAsTextFile action, we can write the RDD to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping the SparkSession\n",
    "spark_rdd.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g) Aggregate â€“ action**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Aggregate the elements of each partition, and then the results for all the partitions, using a given combine functions â€œcombOpâ€ and a neutral â€œzero value.â€\n",
    "\n",
    ">The first function (seqOp) can return a different result type, U, than the type of this RDD. Thus, we need one operation for merging a T into an U and one operation for merging two U\n",
    "    \n",
    ">**SYNTAX:** aggregate(*zeroValue*, *seqOp*, *combOp*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/28 18:01:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Import SparSession module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a new Sparksession\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('OtherActionFunctions')\\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First SparkContext\n",
    "data=[(\"Z\", 1),(\"A\", 20),(\"B\", 30),(\"C\", 40),(\"B\", 30),(\"B\", 60)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second SparkContext\n",
    "my_list = [1,2,3,4,5,3,2]\n",
    "\n",
    "\n",
    "list_rdd = spark.sparkContext.parallelize(my_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#aggregate\n",
    "\n",
    "\n",
    "seqOp = (lambda x, y: (x[0] + y, x[1] +1))\n",
    "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "agg = list_rdd.aggregate((0,0), seqOp, combOp)\n",
    "print(agg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h) Random Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Z', 1), ('B', 30), ('B', 60)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data = [(\"Z\", 1), (\"A\", 20), (\"B\", 30), (\"C\", 40), (\"B\", 30), (\"B\", 60)]\n",
    "\n",
    "sampled_data = random.sample(data, k=min(3, len(data)))\n",
    "print(sampled_data)\n",
    "\n",
    "# Randomly sample 15 items from the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', 30), ('C', 40), ('B', 30), ('B', 60)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd_data = spark.sparkContext.parallelize(data)\n",
    "\n",
    "\n",
    "filtered_data = rdd_data.filter(lambda x: x[1]>=30)\n",
    "\n",
    "print(filtered_data.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) reduce() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*reduce()* â€“ Reduces the elements of the dataset using the specified binary operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#reduce\n",
    "from operator import add\n",
    "\n",
    "redres = list_rdd.reduce(add)\n",
    "\n",
    "print(redres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**j) count, countApprox, countApproxDistinct**\n",
    "\n",
    "\n",
    ">+ **count()** â€“ Return the count of elements in the dataset.\n",
    "\n",
    ">+ **countApprox()** â€“ Return approximate count of elements in the dataset, this method returns incomplete when execution time meets timeout.\n",
    "\n",
    ">+ **countApproxDistinct()** â€“ Return an approximate number of distinct elements in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#count \n",
    "\n",
    "print(list_rdd.count())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#countApprox \n",
    "\n",
    "#countApproxDistinct\n",
    "\n",
    "print(list_rdd.countApproxDistinct())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K) countByValue() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*ountByValue()* â€“ Return Map[T,Long] key representing each unique value in dataset and value represents count each value present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 2, 3: 2, 4: 1, 5: 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countByValue()\n",
    "\n",
    "count_by_value = list_rdd.countByValue()\n",
    "\n",
    "count_by_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L) top() function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*top()* â€“ Return top n elements from the dataset.\n",
    "\n",
    ">**Note:** Use this method only when the resulting array is small, as all the data is loaded into the driverâ€™s memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top\n",
    "\n",
    "top_value = list_rdd.top(3)\n",
    "\n",
    "top_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M) take, takeOrdered, takeSample**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**take()** â€“ Return the first num elements of the dataset.\n",
    "\n",
    ">**takeOrdered()** â€“ Return the first num (smallest) elements from the dataset and this is the opposite of the take() action.\n",
    ">+ Note: Use this method only when the resulting array is small, as all the data is loaded into the driverâ€™s memory.\n",
    "\n",
    ">**takeSample()** â€“ Return the subset of the dataset in an Array.\n",
    ">+ Note: Use this method only when the resulting array is small, as all the data is loaded into the driverâ€™s memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 2, 2, 3, 3]\n",
      "[2, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#take()\n",
    "\n",
    "print(list_rdd.take(3))\n",
    "\n",
    "#takeOrdered()\n",
    "\n",
    "print(list_rdd.takeOrdered(5))\n",
    "\n",
    "#takeSample()\n",
    "\n",
    "print(list_rdd.takeSample(True, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. PySpark DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is a distributed dataset with named attributes, similar to relational database tables or R/Python data frames, but with advanced optimizations.\n",
    "\n",
    "PySpark DataFrame is similar to Pandas DataFrame, but distributed in a cluster and executes operations in parallel on all machines, unlike Pandas which stores and operates on a single machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1.   Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple approach to manually generate a PySpark DataFrame is to use an existing RDD. First, we'll create a Spark RDD from a List collection by calling the parallelize() method from the SparkContext. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.1.  Using toDF() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">PySpark RDDâ€™s toDF() method is used to create a DataFrame from the existing RDD. Since RDD doesnâ€™t have columns, the DataFrame is created with default column names â€œ_1â€ and â€œ_2â€ as we have two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparSession module\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Sparksession\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('PySparkDataFrame')\\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list of data\n",
    "columns = [\"language\", \"users_count\"]\n",
    "data = [\n",
    "    (\"Java\", \"20000\"),\n",
    "    (\"Python\", \"100000\"),\n",
    "    (\"Scala\", \"3000\"),\n",
    "    (\"C++\", \"50000\"),\n",
    "    (\"JavaScript\", \"150000\"),\n",
    "    (\"Ruby\", \"12000\"),\n",
    "    (\"PHP\", \"40000\"),\n",
    "    (\"C#\", \"60000\"),\n",
    "    (\"Go\", \"8000\"),\n",
    "    (\"Swift\", \"22000\"),\n",
    "    (\"Kotlin\", \"18000\"),\n",
    "    (\"Rust\", \"7000\"),\n",
    "    (\"TypeScript\", \"90000\"),\n",
    "    (\"Perl\", \"5000\"),\n",
    "    (\"R\", \"25000\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallelize the list of data\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- users_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transforming the list of data into DataFrame without columns\n",
    "\n",
    "dfFromRDD1 = rdd.toDF(columns)\n",
    "\n",
    "dfFromRDD1.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to provide column names to the DataFrame use toDF() method with column names as arguments as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data list into DataFrame with columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the datatype of these columns infers to the type of data. We can change this behavior by supplying schema, where we can specify a column name, data type, and nullable for each field/column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|  language|users_count|\n",
      "+----------+-----------+\n",
      "|      Java|      20000|\n",
      "|    Python|     100000|\n",
      "|     Scala|       3000|\n",
      "|       C++|      50000|\n",
      "|JavaScript|     150000|\n",
      "|      Ruby|      12000|\n",
      "|       PHP|      40000|\n",
      "|        C#|      60000|\n",
      "|        Go|       8000|\n",
      "|     Swift|      22000|\n",
      "|    Kotlin|      18000|\n",
      "|      Rust|       7000|\n",
      "|TypeScript|      90000|\n",
      "|      Perl|       5000|\n",
      "|         R|      25000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To see the DataFrame\n",
    "\n",
    "dfFromRDD1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.2  Using createDataFrame() from SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Using createDataFrame() from SparkSession is another way to create manually and it takes rdd object as an argument. and chain with toDF() to specify name to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|        _1|    _2|\n",
      "+----------+------+\n",
      "|      Java| 20000|\n",
      "|    Python|100000|\n",
      "|     Scala|  3000|\n",
      "|       C++| 50000|\n",
      "|JavaScript|150000|\n",
      "|      Ruby| 12000|\n",
      "|       PHP| 40000|\n",
      "|        C#| 60000|\n",
      "|        Go|  8000|\n",
      "|     Swift| 22000|\n",
      "|    Kotlin| 18000|\n",
      "|      Rust|  7000|\n",
      "|TypeScript| 90000|\n",
      "|      Perl|  5000|\n",
      "|         R| 25000|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transforming using createDataFrame() function\n",
    "\n",
    "dfFromRDD2 = spark.createDataFrame(rdd)\n",
    "dfFromRDD2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2. Create DataFrame from List Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will see how to create PySpark DataFrame from a list. These examples would be similar to what we have seen in the above section with RDD, but we use the list data object instead of â€œrddâ€ object to create DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.1 Using createDataFrame() from SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Calling createDataFrame() from SparkSession is another way to create PySpark DataFrame manually, it takes a list object as an argument. and chain with toDF() to specify names to the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|  language|users_count|\n",
      "+----------+-----------+\n",
      "|      Java|      20000|\n",
      "|    Python|     100000|\n",
      "|     Scala|       3000|\n",
      "|       C++|      50000|\n",
      "|JavaScript|     150000|\n",
      "|      Ruby|      12000|\n",
      "|       PHP|      40000|\n",
      "|        C#|      60000|\n",
      "|        Go|       8000|\n",
      "|     Swift|      22000|\n",
      "|    Kotlin|      18000|\n",
      "|      Rust|       7000|\n",
      "|TypeScript|      90000|\n",
      "|      Perl|       5000|\n",
      "|         R|      25000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRDD2 = spark.createDataFrame(data).toDF(*columns)\n",
    "\n",
    "\n",
    "dfFromRDD2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.2 Using createDataFrame() with the Row type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">createDataFrame() has another signature in PySpark which takes the collection of Row type and schema for column names as arguments. To use this first we need to convert our â€œdataâ€ object from the list to list of Row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|  language|users_count|\n",
      "+----------+-----------+\n",
      "|      Java|      20000|\n",
      "|    Python|     100000|\n",
      "|     Scala|       3000|\n",
      "|       C++|      50000|\n",
      "|JavaScript|     150000|\n",
      "|      Ruby|      12000|\n",
      "|       PHP|      40000|\n",
      "|        C#|      60000|\n",
      "|        Go|       8000|\n",
      "|     Swift|      22000|\n",
      "|    Kotlin|      18000|\n",
      "|      Rust|       7000|\n",
      "|TypeScript|      90000|\n",
      "|      Perl|       5000|\n",
      "|         R|      25000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import of the Row module\n",
    "from pyspark.sql import Row\n",
    "\n",
    "rowData = map(lambda x: Row(*x), data)\n",
    "\n",
    "\n",
    "dfFromRDD3 = spark.createDataFrame(rowData, columns)\n",
    "\n",
    "dfFromRDD3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK: write a script that will print out the programming languages with user count greater than 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDD' object has no attribute 'withColumn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m col\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntegerType\n\u001b[0;32m----> 5\u001b[0m dfFromRDD3 \u001b[38;5;241m=\u001b[39m \u001b[43mdfFromRDD3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, dfFromRDD3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcast(IntegerType()))\n\u001b[1;32m      8\u001b[0m dfFromRDD3\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RDD' object has no attribute 'withColumn'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "dfFromRDD3 = dfFromRDD3.withColumn(\"users_count\", dfFromRDD3[\"users_count\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "dfFromRDD3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = dfFromRDD3.filter(col(\"users_count\") > 20000)\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/28 19:48:01 ERROR Executor: Exception in task 3.0 in stage 19.0 (TID 41)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\n",
      "TypeError: '>=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "25/01/28 19:48:01 WARN TaskSetManager: Lost task 3.0 in stage 19.0 (TID 41) (192.168.1.69 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\n",
      "TypeError: '>=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "\n",
      "25/01/28 19:48:01 ERROR TaskSetManager: Task 3 in stage 19.0 failed 1 times; aborting job\n",
      "25/01/28 19:48:01 WARN TaskSetManager: Lost task 0.0 in stage 19.0 (TID 38) (192.168.1.69 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 3 in stage 19.0 failed 1 times, most recent failure: Lost task 3.0 in stage 19.0 (TID 41) (192.168.1.69 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\n",
      "TypeError: '>=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "\n",
      "Driver stacktrace:)\n",
      "25/01/28 19:48:01 WARN TaskSetManager: Lost task 1.0 in stage 19.0 (TID 39) (192.168.1.69 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 3 in stage 19.0 failed 1 times, most recent failure: Lost task 3.0 in stage 19.0 (TID 41) (192.168.1.69 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\n",
      "TypeError: '>=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "\n",
      "Driver stacktrace:)\n",
      "25/01/28 19:48:01 WARN TaskSetManager: Lost task 2.0 in stage 19.0 (TID 40) (192.168.1.69 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 3 in stage 19.0 failed 1 times, most recent failure: Lost task 3.0 in stage 19.0 (TID 41) (192.168.1.69 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\n",
      "TypeError: '>=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "\n",
      "Driver stacktrace:)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 19.0 failed 1 times, most recent failure: Lost task 3.0 in stage 19.0 (TID 41) (192.168.1.69 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\nTypeError: '>=' not supported between instances of 'str' and 'int'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\nTypeError: '>=' not supported between instances of 'str' and 'int'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m dfFromRDD1 \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\u001b[38;5;241m.\u001b[39mparallelize(data)\n\u001b[1;32m      4\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m dfFromRDD1\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfiltered_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/rdd.py:1833\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1833\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 19.0 failed 1 times, most recent failure: Lost task 3.0 in stage 19.0 (TID 41) (192.168.1.69 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\nTypeError: '>=' not supported between instances of 'str' and 'int'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1239, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/85/_fprjyv976nbz23f44q_19480000gn/T/ipykernel_9524/2393797607.py\", line 4, in <lambda>\nTypeError: '>=' not supported between instances of 'str' and 'int'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "filtered_df = dfFromRDD1.filter(lambda x: x[1]>=30)\n",
    "\n",
    "print(filtered_df.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.3 Create DataFrame with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-----------+----------+--------+----------+------+------+\n",
      "|  firstname|middlename|lastname|       dob|gender|salary|\n",
      "+-----------+----------+--------+----------+------+------+\n",
      "|      Ruben|      Yves| Nkameni|1950-05-28|     M|  5000|\n",
      "|      James|          |    Kent|1991-04-01|     M|  3000|\n",
      "|    Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|     Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|      Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|        Jen|      Mary|   Brown|1980-02-17|     F|  2500|\n",
      "|      David|    Andrew|   Smith|1992-11-12|     M|  4500|\n",
      "|      Susan|    Claire| Johnson|1975-08-03|     F|  3800|\n",
      "|    William|          |  Miller|1989-06-21|     M|  3200|\n",
      "|      Emily|     Grace|   Davis|1995-01-30|     F|  3700|\n",
      "|       John|      Paul|   Clark|1983-07-14|     M|  3900|\n",
      "|     Sophia|          |   Lopez|1990-10-22|     F|  4200|\n",
      "|Christopher|      Alan|  Taylor|1974-05-11|     M|  4300|\n",
      "|       Emma|    Olivia|     Lee|1988-09-07|     F|  2900|\n",
      "|     Daniel|          |  Harris|1985-03-23|     M|  3600|\n",
      "|    Jessica|     Marie|  Martin|1993-12-19|     F|  3400|\n",
      "+-----------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the list collection object\n",
    "\n",
    "data2 = [\n",
    "    ('Ruben', 'Yves', 'Nkameni', '1950-05-28', 'M', 5000),\n",
    "    ('James', '', 'Kent', '1991-04-01', 'M', 3000),\n",
    "    ('Michael', 'Rose', '', '2000-05-19', 'M', 4000),\n",
    "    ('Robert', '', 'Williams', '1978-09-05', 'M', 4000),\n",
    "    ('Maria', 'Anne', 'Jones', '1967-12-01', 'F', 4000),\n",
    "    ('Jen', 'Mary', 'Brown', '1980-02-17', 'F', 2500),\n",
    "    ('David', 'Andrew', 'Smith', '1992-11-12', 'M', 4500),\n",
    "    ('Susan', 'Claire', 'Johnson', '1975-08-03', 'F', 3800),\n",
    "    ('William', '', 'Miller', '1989-06-21', 'M', 3200),\n",
    "    ('Emily', 'Grace', 'Davis', '1995-01-30', 'F', 3700),\n",
    "    ('John', 'Paul', 'Clark', '1983-07-14', 'M', 3900),\n",
    "    ('Sophia', '', 'Lopez', '1990-10-22', 'F', 4200),\n",
    "    ('Christopher', 'Alan', 'Taylor', '1974-05-11', 'M', 4300),\n",
    "    ('Emma', 'Olivia', 'Lee', '1988-09-07', 'F', 2900),\n",
    "    ('Daniel', '', 'Harris', '1985-03-23', 'M', 3600),\n",
    "    ('Jessica', 'Marie', 'Martin', '1993-12-19', 'F', 3400)\n",
    "]\n",
    "\n",
    "# Defining the columns of the dataFrame\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "\n",
    "\n",
    "# Creating the dataFrame\n",
    "df = spark.createDataFrame(data = data2, schema = columns)\n",
    "\n",
    "# Printing the schema\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "# see the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's introduce the \"id\" field for each row, and manually enter the schema by changin the \"dob\" column from String to Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of the different data types\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DateType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the new list object\n",
    "data3 = [\n",
    "    (1, 'James', '', 'Kent', '1991-04-01', 'M', 3000),\n",
    "    (2, 'Michael', 'Rose', '', '2000-05-19', 'M', 4000),\n",
    "    (3, 'Robert', '', 'Williams', '1978-09-05', 'M', 4000),\n",
    "    (4, 'Maria', 'Anne', 'Jones', '1967-12-01', 'F', 4000),\n",
    "    (5, 'Jen', 'Mary', 'Brown', '1980-02-17', 'F', 2500),\n",
    "    (6, 'David', 'Andrew', 'Smith', '1992-11-12', 'M', 4500),\n",
    "    (7, 'Susan', 'Claire', 'Johnson', '1975-08-03', 'F', 3800),\n",
    "    (8, 'William', '', 'Miller', '1989-06-21', 'M', 3200),\n",
    "    (9, 'Emily', 'Grace', 'Davis', '1995-01-30', 'F', 3700),\n",
    "    (10, 'John', 'Paul', 'Clark', '1983-07-14', 'M', 3900),\n",
    "    (11, 'Sophia', '', 'Lopez', '1990-10-22', 'F', 4200),\n",
    "    (12, 'Christopher', 'Alan', 'Taylor', '1974-05-11', 'M', 4300),\n",
    "    (13, 'Emma', 'Olivia', 'Lee', '1988-09-07', 'F', 2900),\n",
    "    (14, 'Daniel', '', 'Harris', '1985-03-23', 'M', 3600),\n",
    "    (15, 'Jessica', 'Marie', 'Martin', '1993-12-19', 'F', 3400),\n",
    "    (16,'Ruben', 'Yves', 'Nkameni', '1950-05-28', 'M', 5000)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# defining the schema by assigning data types to columns\n",
    "columns = StructType([ \\\n",
    "    StructField(\"id\", IntegerType(), True), \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"dob\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataFrame using the arguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the schema of the Dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dob column from StringType to DateType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the schema of the Dataframe to check the changes\n",
    "\n",
    "\n",
    "# Return the final dataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3.  Create DataFrame from external files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real-time mostly you create DataFrame from data source files like CSV, Text, JSON, XML e.t.c.\n",
    "\n",
    "PySpark by default supports many data formats out of the box without importing any libraries and to create DataFrame you need to use the appropriate method available in DataFrameReader class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.1.  Using CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Key parameters you can provide when reading CSV files:\n",
    "\n",
    ">+ **path:** String or list of strings specifying file path(s)\n",
    ">+ **schema:** StructType or string for specifying the schema\n",
    ">+ **sep:** Delimiter used in the CSV file (default is ',')\n",
    ">+ **encoding:** Character encoding of the file\n",
    ">+ **quote:** Character used for quoting\n",
    ">+ **escape:** Character used for escaping quotes\n",
    ">+ **comment:** Character used for comments in the file\n",
    ">+ **header:** Boolean or string indicating if the first line is a header\n",
    ">+ **inferSchema:** Boolean or string to infer column types from data\n",
    ">+ **ignoreLeadingWhiteSpace:** Boolean to trim leading whitespace\n",
    ">+ **ignoreTrailingWhiteSpace:** Boolean to trim trailing whitespace\n",
    ">+ **nullValue:** String representation of null value\n",
    ">+ **dateFormat:** String specifying the date format\n",
    ">+ **timestampFormat:** String specifying the timestamp format\n",
    ">+ **maxColumns:** Maximum number of columns to parse\n",
    ">+ **maxCharsPerColumn:** Maximum characters allowed per column\n",
    ">+ **multiLine:** Boolean allowing multi-line fields\n",
    ">+ **emptyValue:** String representation of empty value\n",
    ">+ **locale:** Locale to use for parsing dates and numbers\n",
    ">+ **lineSep:** Line separator in the input file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv file from my loca; system\n",
    "\n",
    "csv_path = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.4.  DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4.1. Convert the ReviewDateKey to DateType  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Assuming ReviewDateKey is in the format 'yyyyMMdd' as an integer\n",
    "+ Step 1: Convert ReviewDateKey to string\n",
    "+ Step 2: Use to_date to convert to DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4.2.  Create Groups of age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Age groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For minimum age\n",
    "\n",
    "\n",
    "# For maximum age\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4.3.  creating subsets of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  Demographic Information Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Useful for understanding employee demographics and performing demographic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with demographic information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Questions:\n",
    "\n",
    "+ What is the distribution of employees across different age groups, genders, and marital statuses?\n",
    "+ Is there a relationship between education level and job role?\n",
    "+ How does the education field vary by department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age group distribution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.  Compensation and Benefits Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This subset focuses on financial aspects of employment, such as salaries and bonuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with compensation-related information\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Questions:\n",
    "\n",
    "+ How does monthly income vary across departments and job levels, by gender?\n",
    "+ What is the average monthly income for each age group?\n",
    "+ What percentage of employees receive stock options, and how does it correlate with salary hikes?\n",
    "+ Is there a difference in hourly rate based on BusinessTravel frequency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.  Job Role and Department Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for analysing employee distribution across different roles and departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with job role and department information\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Questions:\n",
    "\n",
    "+ What is the distribution of job roles within each department?\n",
    "+ How does job level vary across departments?\n",
    "+ Which department has the most employees with high business travel requirements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Performance and Engagement Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focused on attributes that measure employee engagement, performance, and effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with performance-related information\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Questions:\n",
    "\n",
    "+ How does job satisfaction relate to overtime hours?\n",
    "+ Which departments have the highest job involvement scores?\n",
    "+ What percentage of employees with a high performance rating also have high job involvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Tenure and Experience Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for analysing how long employees have been with the company, as well as their experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with tenure and experience information\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Attrition and Exit Analysis Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing on columns relevant to attrition analysis, which can help in identifying factors influencing employee turnover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with attrition-related information\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Training and Development Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for analysing employee training participation and how it may correlate with performance or satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset with training-related information\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Questions:\n",
    "\n",
    "+ What is the average tenure of employees in each department?\n",
    "+ Do employees who have worked at more companies (higher NumCompaniesWorked) have a shorter average tenure?\n",
    "+ What is the distribution of promotion frequency (YearsSinceLastPromotion) across different experience levels?\n",
    "+ What is the attrition rate across different age groups?\n",
    "+ Which departments have the highest attrition rates, and do these departments also have high overtime levels?\n",
    "+ Is there a relationship between job satisfaction and attrition?\n",
    "+ What is the average salary for employees in each department, and how does it compare to the average\n",
    "+ What is the average number of training sessions attended based on job level?\n",
    "+ Do employees with higher job satisfaction participate in more training sessions?\n",
    "+ Which departments invest the most in training based on the average TrainingTimesLastYear?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract year from the ReviewDate\n",
    "\n",
    "\n",
    "# Extract month from the ReviewDate\n",
    "\n",
    "\n",
    "# Extract day of the week from the ReviewDate\n",
    "\n",
    "\n",
    "# Display the updated DataFrame with new columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working experience & Salary clasification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Create a new feature for tenure category\n",
    "\n",
    "\n",
    "\n",
    "# Create a feature for salary satisfaction\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
